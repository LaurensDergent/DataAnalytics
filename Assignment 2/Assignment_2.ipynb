{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment the goal is to be able to price a game based on an image. This will be done using a convolutional neural network.\n",
    "For this assignment three methods are developed with the goal of pricing the games:\n",
    "1. Building a CNN that does not take into consideration that some screenshots belong to the same game.\n",
    "1. Building a CNN that takes into consideration that some screenshots belong to the same game by using multiple screenshots of a game as input of a multi-branch CNN with a concatenated layer.\n",
    "1. Building a CNN that takes into consideration that some screenshots belong to the same game by stitching the screenshots of a game together to create one large image. This large image is then fed into the CNN.  \n",
    "\n",
    "First, some general pre-processing is discussed. This ensures that the same splits will be used for each method. Then, for each method the pre-processing steps are discussed. Then each model with the necessary evaluation criteria is built. Then, based on the the evaluation metric, the best of the three beforementioned methods is selected. Lastly, some interpretability techniques to get insights on the model is given. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, the necessary packages and data are loaded in. The data with for each game the related price and images are included. Additionally, a path is created to where the images are stored on the local device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the following packages:\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the location of where the images are stored. Adjust to the correct location when running the code!\n",
    "\n",
    "# For Methodologies 1 and 3\n",
    "# image_location = '/Users/sarahguilliams/Desktop/Advanced Analytics in a Big Data World/Assignment2/images'\n",
    "# For Methodology 2\n",
    "image_location = 'D:/images/stitched'\n",
    "\n",
    "#  Load the json datafile\n",
    "file_path = \"dataset.json\"\n",
    "\n",
    "# Open the JSON file and load its contents\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data1 = pd.DataFrame(data) #Make sure that the data has the DataFrame format\n",
    "data1.head() #print the first 5 rows with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "\n",
    "### Exploratory data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a portion of the games. If we want to train on all of the data, set it equal to 1.\n",
    "num_selected_games = int(len(data1))\n",
    "np.random.seed(0) #This is so that we get the same games when training the model.\n",
    "selected_games = data1.sample(n=num_selected_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a boxplot of the feature 'price'\n",
    "feature_data = selected_games['price']\n",
    "\n",
    "# Create a boxplot using matplotlib\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(feature_data)\n",
    "plt.title('Boxplot of {}'.format('feature_name'))\n",
    "plt.ylabel('Values')\n",
    "plt.show()\n",
    "\n",
    "#calculate some quantiles\n",
    "Q1 = feature_data.quantile(0.25)\n",
    "Q2 = feature_data.quantile(0.50)\n",
    "Q3 = feature_data.quantile(0.75)\n",
    "Q4 = feature_data.quantile(0.99)\n",
    "\n",
    "# Calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "print('Q1: ', Q1, 'Q2: ', Q2, 'Q3: ', Q3, 'Q4: ', Q4)\n",
    "#Based on these quantiles its clear that some of these outliers can be taken out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the games that have a price larger than 100 USD from selected games\n",
    "selected_games_no_outliers = selected_games[selected_games['price'] <= 10000]\n",
    "# The dataset also includes 'bundle' games. these bundles contain multiple games. They have a very high price. As they are not in the scope of this model they are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image augmentation\n",
    "\n",
    "It is the same for the different methdologies\n",
    "\n",
    "A key aspect of the pre-processing step is normalizing the images and performing some data augmentations (ex. rotations, flips, ...). When performing this pre-processing account must be taken of the fact that there are over 125k images available. This makes it very difficult to manually load in and augment the images. A workaround for this is by using the ImageDataGenerator function in combination with a flow_from_dataframe function (inspired by the following stackoverflow question: https://stackoverflow.com/questions/41749398/using-keras-imagedatagenerator-in-a-regression-model). The ImageDataGenerator progressively loads images into the memory while training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training images\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, \n",
    "                                                                        rotation_range=45, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "# For the validation images\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "#For the test images\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 224 \n",
    "height = 224 \n",
    "#height width\n",
    "image_size = (height, width)\n",
    "\n",
    "#batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CNN that does not take into consideration that images belong to the same game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key aspect of this assignment is accounting for the fact that a game can have multiple images. Therefore, when splitting the data into the training, validation, test split, this split should be made based on the games and not the seperate images. For this assignment the decision was made to split our data 60/20/20. \n",
    "\n",
    "Note that in order to also create a dataset for validation, a train-test split must be performed two times. In the first split the test set is generated. In the second split, the training set from the initial split is used to generate a training and a validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and validation sets based on games\n",
    "train1_games, test_games = train_test_split(selected_games_no_outliers, test_size=0.2, random_state=42) \n",
    "train_games, val_games = train_test_split(train1_games, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developing the dataframe structure\n",
    "\n",
    "As the flow_from_dataframe function is used, first, a dataset with in first column the screenshot (the feature) and in the second column the price (the target) is created for respectively the training, validation and test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries for DataFrame\n",
    "train_data = []\n",
    "for index, game in train_games.iterrows():\n",
    "    for screenshot in game['screenshots']:\n",
    "        train_data.append({'screenshot': screenshot, 'price': game['price']})\n",
    "\n",
    "# Create DataFrame\n",
    "train_label_df = pd.DataFrame(train_data)\n",
    "\n",
    "# Do the same for the validation set\n",
    "val_data = []\n",
    "for index, game in val_games.iterrows():\n",
    "    for screenshot in game['screenshots']:\n",
    "        val_data.append({'screenshot': screenshot, 'price': game['price']})\n",
    "\n",
    "val_label_df = pd.DataFrame(val_data)\n",
    "\n",
    "\n",
    "# Do the same for the test set\n",
    "test_data = []\n",
    "for index, game in test_games.iterrows():\n",
    "    for screenshot in game['screenshots']:\n",
    "        test_data.append({'screenshot': screenshot, 'price': game['price']})\n",
    "\n",
    "test_label_df = pd.DataFrame(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, apply the generators to the dataframes. These generators will be used as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_label_df, directory=image_location, color_mode= \"rgb\",\n",
    "                                              x_col=\"screenshot\", y_col=\"price\", has_ext=True, \n",
    "                                              class_mode=\"other\", target_size=image_size, shuffle=True,\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe=val_label_df, directory=image_location, color_mode= \"rgb\",\n",
    "                                              x_col=\"screenshot\", y_col=\"price\", has_ext=True, \n",
    "                                              class_mode=\"other\", target_size=image_size, shuffle=True,\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_label_df, directory=image_location, color_mode= \"rgb\",\n",
    "                                              x_col=\"screenshot\", y_col=\"price\", has_ext=True, \n",
    "                                              class_mode=\"other\", target_size=image_size,\n",
    "                                              batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: add an illustration of how image generator adapts the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of the model\n",
    "\n",
    "Using transfer learning (using a pre-trained model)\n",
    "https://keras.io/guides/transfer_learning/\n",
    "Remove the top last layers so these can be trained on our data.\n",
    "https://www.tensorflow.org/guide/keras/transfer_learning\n",
    "https://www.tensorflow.org/tutorials/images/transfer_learning#create_the_base_model_from_the_pre-trained_convnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "inputs= layers.Input(shape=(height, width, 3))\n",
    "\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=False, #Do not use the imagenet at the top\n",
    "    weights=\"imagenet\",\n",
    "    pooling=None\n",
    ")\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Add a layer on top\n",
    "x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "x = layers.Dropout(0.3, name=\"top_dropout\")(x)\n",
    "x = layers.BatchNormalization()(x) # inspired by https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/ \n",
    "outputs = layers.Dense(1, activation = 'relu', name=\"prediction\")(x) # Used ReLu activation function because prices are always positive\n",
    "\n",
    "model = keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: add a nice image with the architecture\n",
    "This code is to save a nice visualisation of the model. Then this visualisation should be put in this spot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "#plot_model(model, \"multi_input_and_output_model_8 _input.png\", show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevention of overfitting\n",
    "\n",
    "Cannot use MAPE because there are prices equal to zero => will not work\n",
    "How we are preventing overfitting:\n",
    "- keeping track of a validation set and early stopping if the validation set has reached its minimum level (so the delta does not increase anymore)\n",
    "- Dropout\n",
    "- Batch normalization\n",
    "\n",
    "Loss function: using rmse \n",
    "This depends on your loss function. In many circumstances it makes sense to give more weight to points further away from the mean--that is, being off by 10 is more than twice as bad as being off by 5. In such cases RMSE is a more appropriate measure of error. https://stats.stackexchange.com/questions/48267/mean-absolute-error-or-root-mean-squared-error \n",
    "\n",
    "\n",
    "\n",
    "As mentioned above, Cyclical Learning Rates enables our learning rate to oscillate back and forth between a lower and upper bound.\n",
    "\n",
    "So, why bother going through all the trouble?\n",
    "\n",
    "Why not just monotonically decrease our learning rate, just as we’ve always done?\n",
    "\n",
    "The first reason is that our network may become stuck in either saddle points or local minima, and the low learning rate may not be sufficient to break out of the area and descend into areas of the loss landscape with lower loss.\n",
    "\n",
    "Secondly, our model and optimizer may be very sensitive to our initial learning rate choice. If we make a poor initial choice in learning rate, our model may be stuck from the very start.\n",
    "\n",
    "Instead, we can use Cyclical Learning Rates to oscillate our learning rate between upper and lower bounds, enabling us to:\n",
    "\n",
    "Have more freedom in our initial learning rate choices.\n",
    "Break out of saddle points and local minima.\n",
    "In practice, using CLRs leads to far fewer learning rate tuning experiments along with near identical accuracy to exhaustive hyperparameter tuning.\n",
    "\n",
    " Loss function: the parameter that is used to optimize the model, i.e. the loss function is minimized by the model\n",
    " Metric: what is used to evaluate the model performance (this can be used to compare different models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cyclical learning rate\n",
    "from keras.callbacks import *\n",
    "from clr_callback import CyclicLR\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.losses import Huber\n",
    "\n",
    "#set the CLR options\n",
    "clr_step_size = int(4 * (len(train_generator)/batch_size)) #see paper https://arxiv.org/pdf/1506.01186\n",
    "base_lr = 1e-7\n",
    "max_lr = 1e-2\n",
    "mode='triangular'\n",
    "\n",
    "\n",
    "# You are using the triangular learning rate policy and\n",
    "#  base_lr (initial learning rate which is the lower boundary in the cycle) is 0.1\n",
    "clr_triangular = CyclicLR(base_lr=base_lr, max_lr=max_lr, step_size=clr_step_size, mode=mode)\n",
    "opt = Adam(0.0005)\n",
    "\n",
    "# Adding an early stopping mechanism\n",
    "EarlyStoppinng = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=1,\n",
    "    start_from_epoch=1,\n",
    ")\n",
    "\n",
    "model.compile(optimizer=opt, loss=Huber(delta=1.0), metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "print(\"Model is compiled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    callbacks=[ EarlyStoppinng, clr_triangular],\n",
    "    steps_per_epoch=train_generator.n//batch_size,\n",
    "    epochs=6,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps = val_generator.n//batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a curve to analyse the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the error\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot how the cyclical learning rate moves\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title(\"CLR - 'triangular' Policy\")\n",
    "plt.plot(clr_triangular.history['iterations'], clr_triangular.history['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mean_absolute_error = model.evaluate(test_generator, steps = test_generator.n//batch_size)\n",
    "print(\"Test MAE:\", mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the figure fitted vs actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for i in range(len(test_label_df)):\n",
    "    filename = test_label_df.iloc[i][\"screenshot\"]\n",
    "    image_path = os.path.join(image_location, filename)\n",
    "    img = keras.utils.load_img(image_path, target_size=(224, 224))\n",
    "\n",
    "\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize the image data\n",
    "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    price_difference = predictions[0][0] - test_label_df.iloc[i][\"price\"]\n",
    "    pred.append({'price': predictions[0][0], 'difference': price_difference})\n",
    "\n",
    "    print('prediction ', i , predictions[0][0] , 'Difference:', price_difference)\n",
    "\n",
    "predictions_test = pd.DataFrame(pred)\n",
    "predictions_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,7))\n",
    "plt.axis([-500, 10000, -500, 10000])\n",
    "plt.scatter(test_label_df['price'], predictions_test['price'])\n",
    "plt.title(\"Test Set: Actual vs predicted price of the video game\")\n",
    "plt.ylabel(\"Predicted price\", size=20)\n",
    "plt.xlabel(\"Actual price\", size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_label_df['price'], predictions_test['price']))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_label_df['price'], predictions_test['price']))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_label_df['price'], predictions_test['price'])))\n",
    "print('R2 score:', metrics.r2_score(test_label_df['price'], predictions_test['price']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of predictions for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image location\n",
    "number = 450\n",
    "print(test_label_df.loc[number, \"screenshot\"])\n",
    "filename = test_label_df.loc[number, \"screenshot\"]\n",
    "\n",
    "# Construct the full path to the image\n",
    "image_path = os.path.join(image_location, filename)\n",
    "\n",
    "# Load and display the image\n",
    "img = keras.utils.load_img(image_path, target_size=(height, width))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "img_array = keras.utils.img_to_array(img)\n",
    "img_array = img_array/255.0\n",
    "img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "print(predictions)\n",
    "print(test_label_df.loc[number, \"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretability using saliency plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#matplotlib inline\n",
    "# Define the image location\n",
    "number1 = 500 #780 is the tanks\n",
    "number2 = 507\n",
    "#print(test_label_df.loc[number, \"screenshot\"])\n",
    "filename1 = test_label_df.loc[number1, \"screenshot\"]\n",
    "price1 = test_label_df.loc[number1, \"price\"]\n",
    "filename2 = test_label_df.loc[number2, \"screenshot\"]\n",
    "price2 = test_label_df.loc[number2, \"price\"]\n",
    "\n",
    "# Construct the full path to the image\n",
    "image_path1 = os.path.join(image_location, filename1)\n",
    "image_path2 = os.path.join(image_location, filename2)\n",
    "\n",
    "# Load and display the image\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "\n",
    "img1 = keras.utils.load_img(image_path1, target_size=(height, width))\n",
    "img2 = keras.utils.load_img(image_path2, target_size=(height, width))\n",
    "\n",
    "f, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(img1)\n",
    "ax[1].imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Github\n",
    "# https://github.com/keisen/tf-keras-vis/tree/master\n",
    "\n",
    "\n",
    "# Preprocess images, so that they are normalized\n",
    "img_array = keras.utils.img_to_array(img1)\n",
    "img_array = img_array / 255.0  # Normalize the image data\n",
    "#print(img_array.shape)\n",
    "#img_array = tensorflow.expand_dims(img_array, 0)  # Create batch axis\n",
    "#print(img_array.shape)\n",
    "\n",
    "# Model modifier: Such that the last layer has a linear activation function.\n",
    "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
    "replace2linear = ReplaceToLinear()\n",
    "\n",
    "#Score function: should return the target score\n",
    "def score(output):\n",
    "    return output[0][0]\n",
    "\n",
    "from tf_keras_vis.saliency import Saliency\n",
    "from tf_keras_vis.utils import num_of_gpus\n",
    "\n",
    "# Create Gradcam object\n",
    "saliency = Saliency(loaded_model,\n",
    "                  model_modifier=replace2linear,\n",
    "                  clone=True)\n",
    "\n",
    "# Generate heatmap with GradCAM\n",
    "saliency_map = saliency(score, img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_title = [price1]\n",
    "# Plot\n",
    "f, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 4))\n",
    "\n",
    "ax.set_title(image_title, fontsize=16)\n",
    "ax.imshow(saliency_map[0], cmap='jet')\n",
    "ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-input CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Developing the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screenshots_new = selected_games_no_outliers['screenshots'].apply(pd.Series)\n",
    "screenshots_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the NaNs with other screenshots. So that in the end have inputs of normal size. The images in the other columns are selected at random from the previous columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace NaN values with a random non-NaN value from previous columns\n",
    "def replace_nan_with_random(df):\n",
    "    for index, row in df.iterrows():\n",
    "        for col_index, value in row.items():\n",
    "            if pd.isnull(value):\n",
    "                # Get previous non-NaN values in the row\n",
    "                previous_values = row[:col_index][::-1]\n",
    "                previous_values = previous_values.dropna()\n",
    "                \n",
    "                if not previous_values.empty:\n",
    "                    # Select a random non-NaN value from previous columns\n",
    "                    random_value = previous_values.sample().iloc[0]\n",
    "                    # Replace NaN with the randomly selected value\n",
    "                    df.at[index, col_index] = random_value\n",
    "\n",
    "# Call the function to replace NaN values with random non-NaN values\n",
    "replace_nan_with_random(screenshots_new)\n",
    "\n",
    "# Add the price\n",
    "result_df = pd.concat([selected_games_no_outliers['price'], screenshots_new], axis=1)\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets based on games\n",
    "train1_games, test_games = train_test_split(result_df, test_size=0.2, random_state=42)\n",
    "train_games, val_games = train_test_split(train1_games, test_size=0.25, random_state=42) # 0.25 * 0.8 = 0.2\n",
    "#train_games.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generator_multiple(generator, dataframe, batch_size, img_height, img_width, num_columns=10):\n",
    "    generators = []\n",
    "    \n",
    "    for i in range(num_columns):\n",
    "        genX = generator.flow_from_dataframe(dataframe=dataframe, directory=image_location, color_mode=\"rgb\",\n",
    "                                             target_size=(img_height, img_width),\n",
    "                                             x_col=i, y_col=\"price\", has_ext=True,\n",
    "                                             class_mode=\"other\",\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             seed=7)\n",
    "        generators.append(genX)\n",
    "       \n",
    "\n",
    "    while True:\n",
    "        batch_X = []\n",
    "        batch_Y = None\n",
    "        \n",
    "        for genX in generators:\n",
    "            X, Y = genX.next()\n",
    "            batch_X.append(X)\n",
    "            if batch_Y is None:\n",
    "                batch_Y = Y\n",
    "        \n",
    "        yield batch_X, batch_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputgenerator=generate_generator_multiple(generator=train_datagen, dataframe=train_games,\n",
    "                                           batch_size=batch_size,\n",
    "                                           img_height=height,\n",
    "                                           img_width=width)       \n",
    "\n",
    "valgenerator=generate_generator_multiple(val_datagen, dataframe=val_games,\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=height,\n",
    "                                          img_width=width)   \n",
    "     \n",
    "testgenerator=generate_generator_multiple(test_datagen, dataframe=test_games,\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=height,\n",
    "                                          img_width=width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Concatenate, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "\n",
    "input_x_1 = Input(shape=(224, 224, 3), name='input_1')\n",
    "input_x_2 = Input(shape=(224, 224, 3), name='input_2')\n",
    "input_x_3 = Input(shape=(224, 224, 3), name='input_3')\n",
    "input_x_4 = Input(shape=(224, 224, 3), name='input_4')\n",
    "input_x_5 = Input(shape=(224, 224, 3), name='input_5')\n",
    "input_x_6 = Input(shape=(224, 224, 3), name='input_6')\n",
    "input_x_7 = Input(shape=(224, 224, 3), name='input_7')\n",
    "input_x_8 = Input(shape=(224, 224, 3), name='input_8')\n",
    "input_x_9 = Input(shape=(224, 224, 3), name='input_9')\n",
    "input_x_10 = Input(shape=(224, 224, 3), name='input_10')\n",
    "\n",
    "#Shared layer\n",
    "base_model = ResNet50(\n",
    "    include_top=False, #Do not use the imagenet at the top\n",
    "    weights=\"imagenet\",\n",
    "    input_shape= (224, 224, 3),\n",
    "    pooling=None\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "x1 = base_model(input_x_1, training=False)\n",
    "x2 = base_model(input_x_2, training=False)\n",
    "x3 = base_model(input_x_3, training=False)\n",
    "x4 = base_model(input_x_4, training=False)\n",
    "x5 = base_model(input_x_5, training=False)\n",
    "x6 = base_model(input_x_6, training=False)\n",
    "x7 = base_model(input_x_7, training=False)\n",
    "x8 = base_model(input_x_8, training=False)\n",
    "x9 = base_model(input_x_9, training=False)\n",
    "x10 = base_model(input_x_10, training=False)\n",
    "\n",
    "x = Concatenate()([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10])\n",
    "\n",
    "# Add a layer on top\n",
    "x = GlobalAveragePooling2D(name=\"avg_pool\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.3, name=\"top_dropout\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "# inspired by https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/ \n",
    "outputs = Dense(1, activation = 'relu', name=\"prediction\")(x) # Used ReLu activation function because prices are always positive\n",
    "\n",
    "model = Model(inputs= [input_x_1, input_x_2, input_x_3, input_x_4, input_x_5, input_x_6, input_x_7, input_x_8, input_x_9, input_x_10], outputs= outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do: add nice image with the architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "#plot_model(model, \"multi_input_and_output_model_8 _input.png\", show_shapes=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding cyclical learning rate\n",
    "from keras.callbacks import *\n",
    "from clr_callback import CyclicLR\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "#set the CLR options\n",
    "clr_step_size = int(4 * (len(train_games)/batch_size)) #see paper https://arxiv.org/pdf/1506.01186\n",
    "base_lr = 1e-7\n",
    "max_lr = 5e-2\n",
    "mode='triangular'\n",
    "\n",
    "\n",
    "# You are using the triangular learning rate policy and\n",
    "#  base_lr (initial learning rate which is the lower boundary in the cycle) is 0.1\n",
    "clr_triangular = CyclicLR(base_lr=base_lr, max_lr=max_lr, step_size=clr_step_size, mode=mode)\n",
    "opt = Adam(0.0007)\n",
    "\n",
    "# Adding an early stopping mechanism\n",
    "EarlyStopping_cb = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=1,\n",
    "    verbose=1,\n",
    "    start_from_epoch=0)\n",
    "\n",
    "model.compile(optimizer=opt, loss='mean_absolute_error', metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "print(\"Model is compiled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "\n",
    "history = model.fit(\n",
    "    inputgenerator,\n",
    "    steps_per_epoch=len(train_games)//batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=testgenerator,\n",
    "    validation_steps = len(test_games)//batch_size, \n",
    "    callbacks = [EarlyStopping_cb , clr_triangular]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the error\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['val_mean_absolute_error'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "loss, mean_absolute_error = model.evaluate(valgenerator, steps=len(val_games)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "\n",
    "for i in range(len(test_games)):\n",
    "\n",
    "    image_paths = [os.path.join(image_location, filename) for filename in test_games.iloc[i, 1:11]]  # Assuming columns \"0\" to \"8\" contain the image filenames\n",
    "    images = [keras.utils.load_img(image_path, target_size=(224, 224)) for image_path in image_paths]\n",
    "\n",
    "    img_arrays = [keras.utils.img_to_array(img) for img in images]\n",
    "    img_arrays = [img_array / 255.0 for img_array in img_arrays]\n",
    "    img_arrays = [tensorflow.expand_dims(img_array, 0) for img_array in img_arrays]  # Create batch axis for each image\n",
    "\n",
    "\n",
    "    predictions = model.predict(img_arrays)\n",
    "    price_difference = predictions[0][0] - test_games.iloc[i]['price']\n",
    "    pred.append({'price': predictions[0][0], 'difference': price_difference})\n",
    "    print('prediction ', i , predictions[0][0] , 'Difference:', price_difference)\n",
    "\n",
    "predictions_test = pd.DataFrame(pred)\n",
    "predictions_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (7,7))\n",
    "plt.axis([-100, 1000, -100, 1000])\n",
    "plt.scatter(test_games['price'], predictions_test['price'])\n",
    "#plt.plot([min(test_games['price']), max(test_games['price'])], [min(test_games['price']), max(test_games['price'])], color=\"r\", linestyle=\"-\", linewidth=2)\n",
    "#plt.plot([min(test_games['price']), max(test_games['price'])], [min(test_games['price']), max(test_games['price'])], color=\"r\", linestyle=\"-\", linewidth=2)\n",
    "plt.title(\"test set actual vs predicted\")\n",
    "plt.ylabel(\"Predicted\", size=20)\n",
    "plt.xlabel(\"Actual\", size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_games['price'], predictions_test['price']))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_games['price'], predictions_test['price']))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_games['price'], predictions_test['price'])))\n",
    "print('R2 score:', metrics.r2_score(test_games['price'], predictions_test['price']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stitched images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following part attempts to predict the price of a game based on one input of multiple screenshots. The screenshots will be stitched together per game. As in the part before a prediction was made for every screenshot without a link to the other screenshots of the game. This part tries to improve the model by linking all screenshots together and giving one input per game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in dataframe that contains the name of the first screenshot used in the stitching of the images and the price of the game. \n",
    "df = pd.read_csv('stitched_price.csv')\n",
    "\n",
    "image_location = 'D:/images/stitched'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the new dataframe the preprocessing has to be repeated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a portion of the games. If we want to train on all of the data, set it equal to 1.\n",
    "num_selected_games = int(len(df)*0.1)\n",
    "np.random.seed(0) #This is so that we get the same games when training the model.\n",
    "selected_games = df.sample(n=num_selected_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the games that have a price larger than 100 USD from selected games\n",
    "selected_games_no_outliers = selected_games[selected_games['price'] <= 10000]\n",
    "# The dataset also includes 'bundle' games. these bundles contain multiple games. They have a very high price. As they are not in the scope of this model they are removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-do train test split because are working with a different dataframe than the origianl json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split data into training and validation sets based on games\n",
    "train1_games, test_games = train_test_split(selected_games_no_outliers, test_size=0.2, random_state=42) \n",
    "train_games, val_games = train_test_split(train1_games, test_size=0.2, random_state=42) # 0.25 * 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_games['price'] = val_games['price'].astype('float32')\n",
    "test_games['price'] = test_games['price'].astype('float32')\n",
    "train_games['price'] =train_games['price'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 937 entries, 13676 to 9473\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   screenshot  937 non-null    object \n",
      " 1   price       937 non-null    float32\n",
      "dtypes: float32(1), object(1)\n",
      "memory usage: 18.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape price\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "test_games['price'] = target_scaler.fit_transform(test_games[['price']].values)\n",
    "train_games['price'] = target_scaler.fit_transform(train_games[['price']].values)\n",
    "val_games['price'] = target_scaler.fit_transform(val_games[['price']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 750 validated image filenames.\n",
      "Found 47 validated image filenames.\n",
      "Found 293 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "#create a training datagenerator, including data augmentation\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, \n",
    "                                                                        rotation_range=45, horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_games, directory=image_location, \n",
    "                                              x_col=\"screenshot\", y_col=\"price\", has_ext=True, \n",
    "                                              class_mode=\"other\", target_size=(224, 224), \n",
    "                                              batch_size=32)\n",
    "\n",
    "\n",
    "\n",
    "# same for the test set\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "val_generator = test_datagen.flow_from_dataframe(dataframe=val_games, directory=image_location, \n",
    "                                              x_col=\"screenshot\", y_col=\"price\", has_ext=True, \n",
    "                                              class_mode=\"other\", target_size=(224, 224), \n",
    "                                              batch_size=32)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_games, directory=image_location, \n",
    "                                              x_col=\"screenshot\", y_col=\"price\", has_ext=True, \n",
    "                                              class_mode=\"other\", target_size=(224, 224), \n",
    "                                              batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(None,None, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "c:\\Users\\Laure\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 3s/step - loss: 7.8598 - mae: 1.0659 - val_loss: 0.0188 - val_mae: 0.0834\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.0199 - mae: 0.0763\n",
      "Validation Mean Absolute Error: 0.08381935209035873\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "model = Sequential([base_model])\n",
    "# Add layers to the base model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', padding = \"same\", input_shape=(224,224, 3)), #add multiple convolution layers\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding = \"same\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding = \"same\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    # Dropout(0.20),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=1, \n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "loss, mae = model.evaluate(val_generator)\n",
    "print(\"Validation Mean Absolute Error:\", mae)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"fullModel_3epochs.keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "difference  0 -0.0055518784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  1 0.04372716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  2 -0.14221658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  3 -0.06623841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  4 -0.4939907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  5 -0.2367157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  6 0.00886308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  7 0.027286615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  8 -0.35285985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  9 0.06661465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  10 0.05751232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  11 -0.07777598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  12 -0.24706274\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  13 -0.31452265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  14 -0.016141348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  15 -0.0526362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  16 -0.07096466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  17 -0.060314454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  18 0.025950562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  19 0.05965361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  20 -0.025080085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  21 -0.13865703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  22 -0.7382588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  23 0.077978946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  24 -0.23266843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  25 -0.28325617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  26 -0.010137964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  27 0.056054108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  28 -0.25011632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  29 0.09298454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  30 -0.19138634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  31 0.037419613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  32 -0.027873568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  33 -0.04386174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  34 -0.15803587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  35 -0.15015486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  36 -0.08109541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  37 0.059561253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  38 0.026929876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  39 0.06284576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  40 -0.2603004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  41 0.042762794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  42 -0.061306268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  43 -0.13418435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  44 -0.11257458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  45 -0.48183957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  46 0.048091084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  47 -0.37423116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  48 -0.38431317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  49 -0.03432948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  50 0.060607053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  51 -0.095490254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  52 -0.16474816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  53 -0.60092217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  54 -0.4985512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  55 -0.004659623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  56 -0.04450115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  57 -0.8566881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  58 -0.06491627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  59 -0.07055559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  60 -0.025401443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  61 0.025881395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  62 -0.6103705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  63 -0.12396773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  64 -0.07085254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  65 -0.09304158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  66 -0.1865996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  67 -0.15856016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  68 -0.023213744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  69 -0.29889265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  70 -0.26486403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  71 -0.118322775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  72 -0.3793706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  73 -0.12373069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  74 -0.32712036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  75 0.041705042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  76 0.040642984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  77 -0.012950391\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  78 -0.005982103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  79 -0.49999112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  80 -0.073811844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  81 0.03910114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  82 0.042116128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  83 -0.07311101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  84 0.0178055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  85 -0.29274663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  86 -0.06726034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  87 -0.22706023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  88 -0.23438156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  89 -0.2107243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  90 -0.1180456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  91 -0.31738597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  92 -0.2778823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  93 -0.24082938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  94 -0.26017892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  95 -0.12697323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  96 0.04562942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "difference  97 -0.031476423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "difference  98 -0.11517724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "difference  99 0.019007493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "difference  100 0.04045646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  101 -0.13602823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  102 -0.004224889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "difference  103 -0.048919536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  104 -0.056542285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  105 -0.6152193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  106 -0.11279562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  107 -0.022411808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  108 -0.06302319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  109 -0.04376194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  110 -0.24399856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  111 -0.0011090115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  112 -0.059245504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  113 0.005591426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  114 0.024630208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  115 0.046509378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "difference  116 0.007914666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  117 -0.031103432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  118 0.02885232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  119 -0.28863823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  120 -0.16183773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  121 0.050463833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  122 -0.050582282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  123 -0.01227814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  124 0.057558037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  125 0.03927079\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  126 0.014191661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  127 0.044509377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  128 -0.29484004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  129 -0.1169243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "difference  130 -0.07473273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  131 -0.4119811\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  132 -0.27458677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  133 0.029225662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  134 -0.5126819\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  135 0.04019484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  136 -0.12629688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  137 -0.6453174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  138 -0.013640821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  139 -0.0071289204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  140 -0.074166365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  141 -0.034851484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "difference  142 0.00011858344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  143 -0.04875438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  144 -0.0841988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  145 -0.40975714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  146 0.053469002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  147 -0.17163284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  148 -0.29163975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  149 -0.014363483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  150 -0.32795075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  151 0.03481839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  152 -0.50492626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  153 -0.61122465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  154 0.022988876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  155 -0.14552385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  156 0.036740422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  157 -0.38242725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  158 -0.06532951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "difference  159 -0.045627393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  160 -0.2200786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  161 -0.14192963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  162 -0.08829277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  163 0.02382469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  164 0.034749396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  165 0.021980397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  166 -0.037170716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  167 -0.16972229\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  168 0.06700255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  169 -0.5003866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  170 -0.056679994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  171 -0.16244844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  172 -0.10423434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  173 0.03186219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  174 -0.14310585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  175 -0.099578716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  176 -0.14283875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  177 0.01019536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  178 -0.16489755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  179 -0.1737171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  180 0.03646726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  181 -0.028938264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  182 -0.22789812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  183 -0.38070855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  184 -0.115744516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  185 -0.022795253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  186 -0.053126663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  187 -0.0006316975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  188 -0.51513684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  189 -0.038380355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  190 -0.27720144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  191 0.05926644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  192 -0.6268617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  193 0.022209873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  194 0.034441747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  195 0.0015354641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  196 -0.20403323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  197 -0.046460785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  198 -0.04977318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  199 -0.02327963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  200 -0.03786987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  201 -0.24586716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  202 -0.27662215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  203 -0.93619525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  204 -0.8568548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  205 -0.16272222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "difference  206 -0.0069603994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  207 0.023686586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  208 -0.031313464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "difference  209 0.028378738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  210 -0.014857762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  211 -0.07161492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  212 0.07146451\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  213 -0.21450636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "difference  214 -0.04571213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  215 0.06892366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  216 -0.026643798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  217 -0.18566473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  218 0.06086304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  219 0.010900786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  220 -0.0028367452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  221 -0.022806227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  222 -0.06669088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  223 -0.042178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  224 0.059728235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  225 -0.25968683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  226 0.040426977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  227 0.028715922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  228 -0.0029901266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  229 -0.073374934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "difference  230 -0.26487717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  231 -0.2767239\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  232 -0.024496786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  233 -0.38090283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  234 0.03831156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  235 -0.17377572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  236 -0.1546885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  237 -0.055022873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  238 0.002747137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  239 -0.097506866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "difference  240 0.0063376166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  241 -0.02304595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  242 0.090372585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  243 0.038347967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  244 -0.0046807528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  245 -0.38481942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  246 -0.8484813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  247 -0.1581913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  248 0.018125955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  249 0.009945001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  250 -0.041643806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  251 0.032338575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  252 -0.33745852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  253 -0.35001332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  254 -0.658383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  255 -0.05211544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  256 -0.06303212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  257 -0.061461948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  258 -0.098503895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  259 0.029350761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  260 -0.25439072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  261 -0.30855498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  262 -0.08856314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  263 -0.16922875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  264 0.03113926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  265 -0.62648565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  266 -0.1158136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  267 -0.09750453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  268 0.034626596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  269 -0.37726068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  270 -0.15513043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  271 -0.40289673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  272 -0.056247137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  273 -0.28780782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "difference  274 -0.09777174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  275 0.07375109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  276 0.014466589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  277 0.05973117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  278 -0.094724044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  279 -0.113686934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  280 -0.16962425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  281 -0.12121549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  282 0.0710772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  283 -0.080921315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "difference  284 -0.07537275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  285 0.02344298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "difference  286 -0.116343684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  287 -0.020675644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "difference  288 0.044590525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "difference  289 0.07240912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "difference  290 -0.08164778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "difference  291 -0.0055598393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "difference  292 0.023683881\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price\n",
       "0  0.039686\n",
       "1  0.066232\n",
       "2  0.034642\n",
       "3  0.047196\n",
       "4  0.062954"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = keras.models.load_model(\"my_model.keras\")\n",
    "\n",
    "pred = []\n",
    "\n",
    "for i in range(len(test_games)):\n",
    "    filename = test_games.iloc[i][\"screenshot\"]\n",
    "    image_path = os.path.join(image_location, filename)\n",
    "    img = keras.utils.load_img(image_path, target_size=(224, 224))\n",
    "\n",
    "\n",
    "    img_array = keras.utils.img_to_array(img)\n",
    "    img_array = img_array / 255.0  # Normalize the image data\n",
    "    img_array = keras.ops.expand_dims(img_array, 0)  # Create batch axis\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    pred.append({'price': predictions[0][0]})\n",
    "\n",
    "    print('difference ', i , predictions[0][0] - test_games.iloc[i][\"price\"])\n",
    "\n",
    "predictions_test = pd.DataFrame(pred)\n",
    "predictions_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.14446115\n",
      "Mean Squared Error: 0.050466783\n",
      "Root Mean Squared Error: 0.22464813\n",
      "R2 score: -0.43554704962810864\n",
      "Mean absolute percentage error: 29122443000000.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_games['price'], predictions_test['price']))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_games['price'], predictions_test['price']))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_games['price'], predictions_test['price'])))\n",
    "print('R2 score:', metrics.r2_score(test_games['price'], predictions_test['price']))\n",
    "print('Mean absolute percentage error:', metrics.mean_absolute_percentage_error(test_games['price'], predictions_test['price']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Actual')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the predicted vs actual values\n",
    "plt.figure(figsize = (7,7))\n",
    "plt.scatter(test_games['price'], predictions_test['price'])\n",
    "plt.plot([min(test_games['price']), max(test_games['price'])], [min(test_games['price']), max(test_games['price'])], color=\"r\", linestyle=\"-\", linewidth=2)\n",
    "plt.title(\"test set actual vs predicted\")\n",
    "plt.ylabel(\"Predicted\", size=20)\n",
    "plt.xlabel(\"Actual\", size=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
